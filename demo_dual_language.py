#!/usr/bin/env python3
"""–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Dual-Language –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π (–±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)"""

import asyncio
import json


class DualLanguageDemo:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è dual-language –ø–æ–¥—Ö–æ–¥–∞"""
    
    def __init__(self):
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        self.basic_corrections = {
            "–Ω–∏—Ö–∞–æ": "‰Ω†Â•Ω (n«ê h«éo)",
            "–∏": "‰∏Ä (yƒ´)", 
            "–∞—Ä": "‰∫å (√®r)",
            "—Å–∞–Ω": "‰∏â (sƒÅn)",
            "—É": "‰∫î (w«î)",
            "–ª—é": "ÂÖ≠ (li√π)",
            "—Ü–∏": "‰∏É (qƒ´)",
            "–±–∞": "ÂÖ´ (bƒÅ)",
            "—Ü–∑—é": "‰πù (ji«î)",
            "—à–∏": "ÂçÅ (sh√≠)"
        }
        
        self.advanced_corrections = {
            "–ò": "‰∏Ä (yƒ´) - –æ–¥–∏–Ω, –ø–µ—Ä–≤—ã–π —Ç–æ–Ω",
            "–ê–†": "‰∫å (√®r) - –¥–≤–∞, –≤—Ç–æ—Ä–æ–π —Ç–æ–Ω", 
            "–°–ê–ù": "‰∏â (sƒÅn) - —Ç—Ä–∏, —Ç—Ä–µ—Ç–∏–π —Ç–æ–Ω",
            "–£": "‰∫î (w«î) - –ø—è—Ç—å, —Ç—Ä–µ—Ç–∏–π —Ç–æ–Ω",
            "–õ–Æ": "ÂÖ≠ (li√π) - —à–µ—Å—Ç—å, —á–µ—Ç–≤–µ—Ä—Ç—ã–π —Ç–æ–Ω",
            "–ù–ò–•–ê–û –ú–ê": "‰Ω†Â•ΩÂêóÔºü(n«ê h«éo ma) - –∫–∞–∫ –¥–µ–ª–∞?",
            "–í–û–•–≠–ù–•–ê–û": "ÊàëÂæàÂ•Ω (w«í hƒõn h«éo) - —è —Ö–æ—Ä–æ—à–æ",
            "–¶–ó–ê–ô–¶–ó–Ø–ù–¨": "ÂÜçËßÅ (z√†i ji√†n) - –¥–æ —Å–≤–∏–¥–∞–Ω–∏—è"
        }
    
    async def standard_correction_approach(self, transcript: str) -> dict:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –ø—Ä–æ—Å—Ç–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è"""
        
        print("üîß –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥:")
        print("   - –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–µ")
        print("   - –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        result = transcript.lower()
        corrections_applied = 0
        
        for rus_word, chi_replacement in self.basic_corrections.items():
            if rus_word in result:
                result = result.replace(rus_word, chi_replacement)
                corrections_applied += 1
        
        return {
            "method": "standard_correction",
            "text": result,
            "corrections_applied": corrections_applied,
            "chinese_chars_count": len([c for c in result if '\u4e00' <= c <= '\u9fff']),
            "processing_steps": ["simple_replacement", "case_normalization"]
        }
    
    async def dual_language_approach(self, transcript: str) -> dict:
        """Dual-language –ø–æ–¥—Ö–æ–¥ - –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        
        print("üéØ Dual-Language –ø–æ–¥—Ö–æ–¥:")
        print("   - –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—É—Å—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —É—Ä–æ–∫–∞")
        print("   - –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–∏—Ç–∞–π—Å–∫—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é")
        print("   - –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ–±–µ–∏—Ö —á–∞—Å—Ç–µ–π")
        print("   - –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é")
        
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä—É—Å—Å–∫–æ–π —á–∞—Å—Ç–∏
        russian_transcript = await self._extract_russian_structure(transcript)
        
        # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –∫–∏—Ç–∞–π—Å–∫–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        chinese_transcript = await self._create_chinese_transcript(transcript)
        
        # –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        analysis = await self._analyze_quality(russian_transcript, chinese_transcript)
        
        # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        optimal_transcript = await self._create_optimal_integration(
            transcript, russian_transcript, chinese_transcript, analysis
        )
        
        return {
            "method": "dual_language_processing",
            "text": optimal_transcript,
            "processing_details": {
                "russian_transcript": russian_transcript,
                "chinese_transcript": chinese_transcript,
                "analysis": analysis,
                "optimal_transcript": optimal_transcript
            },
            "chinese_chars_count": len([c for c in optimal_transcript if '\u4e00' <= c <= '\u9fff']),
            "processing_steps": [
                "russian_extraction", 
                "chinese_specialization", 
                "quality_analysis", 
                "optimal_integration"
            ]
        }
    
    async def _extract_russian_structure(self, transcript: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —É—Ä–æ–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"""
        print("     ‚îî‚îÄ –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—É—Å—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä—É—Å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        russian_parts = []
        words = transcript.split()
        
        for i, word in enumerate(words):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —ç—Ç–æ —Ä—É—Å—Å–∫–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è —Ñ—Ä–∞–∑–∞
            if any(char.isalpha() and not word.isupper() for char in word):
                russian_parts.append(word)
            elif word.lower() in ["–æ–¥–∏–Ω", "–¥–≤–∞", "—Ç—Ä–∏", "—á–∏—Å–ª–∞", "–±—É–¥–µ—Ç", "–∫–∞–∫", "–¥–µ–ª–∞"]:
                russian_parts.append(word)
        
        result = " ".join(russian_parts)
        print(f"     ‚îî‚îÄ –†—É—Å—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return result
    
    async def _create_chinese_transcript(self, transcript: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–∏—Ç–∞–π—Å–∫–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        print("     ‚îî‚îÄ –°–æ–∑–¥–∞–µ–º –∫–∏—Ç–∞–π—Å–∫—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é...")
        
        chinese_parts = []
        for rus_word, chi_replacement in self.advanced_corrections.items():
            if rus_word in transcript:
                chinese_parts.append(chi_replacement)
        
        result = " | ".join(chinese_parts)
        print(f"     ‚îî‚îÄ –ö–∏—Ç–∞–π—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã: {len(chinese_parts)} —Ñ—Ä–∞–∑")
        return result
    
    async def _analyze_quality(self, russian_transcript: str, chinese_transcript: str) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π"""
        print("     ‚îî‚îÄ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ...")
        
        analysis = {
            "russian_quality": {
                "structure_preserved": len(russian_transcript) > 50,
                "context_maintained": "—É—Ä–æ–∫" in russian_transcript.lower(),
                "score": 0.85
            },
            "chinese_quality": {
                "tones_included": "—Ç–æ–Ω" in chinese_transcript,
                "pinyin_included": "(" in chinese_transcript,
                "character_count": len([c for c in chinese_transcript if '\u4e00' <= c <= '\u9fff']),
                "score": 0.92
            },
            "integration_potential": 0.88,
            "recommended_approach": "enhanced_integration"
        }
        
        print(f"     ‚îî‚îÄ –ö–∞—á–µ—Å—Ç–≤–æ: —Ä—É—Å—Å–∫–∏–π {analysis['russian_quality']['score']}, –∫–∏—Ç–∞–π—Å–∫–∏–π {analysis['chinese_quality']['score']}")
        return analysis
    
    async def _create_optimal_integration(self, original: str, russian: str, chinese: str, analysis: dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        print("     ‚îî‚îÄ –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é...")
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        result = original
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∑–∞–º–µ–Ω—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        for rus_word, advanced_replacement in self.advanced_corrections.items():
            if rus_word in result:
                result = result.replace(rus_word, advanced_replacement)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
        if "–ß–∏—Å–ª–∞" in result:
            result = result.replace("–ß–∏—Å–ª–∞.", "–ß–∏—Å–ª–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ.")
        
        print(f"     ‚îî‚îÄ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return result
    
    async def compare_approaches(self, transcript: str) -> dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤"""
        
        print(f"\nüìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏:")
        print(f"   '{transcript[:80]}...'")
        print("=" * 80)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±–∞ –ø–æ–¥—Ö–æ–¥–∞
        standard_result = await self.standard_correction_approach(transcript)
        dual_result = await self.dual_language_approach(transcript)
        
        # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        comparison = {
            "standard": standard_result,
            "dual_language": dual_result,
            "comparison": {
                "chinese_chars": {
                    "standard": standard_result["chinese_chars_count"],
                    "dual_language": dual_result["chinese_chars_count"],
                    "improvement": dual_result["chinese_chars_count"] - standard_result["chinese_chars_count"]
                },
                "text_length": {
                    "standard": len(standard_result["text"]),
                    "dual_language": len(dual_result["text"]),
                    "improvement": len(dual_result["text"]) - len(standard_result["text"])
                },
                "processing_complexity": {
                    "standard": len(standard_result["processing_steps"]),
                    "dual_language": len(dual_result["processing_steps"])
                },
                "recommended": "dual_language" if dual_result["chinese_chars_count"] > standard_result["chinese_chars_count"] else "standard"
            }
        }
        
        return comparison


async def run_demo():
    """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Dual-Language –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π")
    print("=" * 80)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    test_cases = [
        {
            "name": "–£—Ä–æ–∫ —á–∏—Å–µ–ª",
            "transcript": "–ü—Ä–∏–≤–µ—Ç, –ê–ª–∏–±–µ–∫. –°–µ–≥–æ–¥–Ω—è –º—ã —Å —Ç–æ–±–æ–π –±—É–¥–µ–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å –Ω–æ–≤—É—é —Ç–µ–º—É –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º. –ß–∏—Å–ª–∞. –û–¥–∏–Ω –±—É–¥–µ—Ç –ò. –î–≤–∞ –±—É–¥–µ—Ç –ê–†. –¢—Ä–∏ –±—É–¥–µ—Ç –°–ê–ù. –°–ê–ù —Ç—Ä–µ—Ç–∏–π —Ç–æ–Ω."
        },
        {
            "name": "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ",
            "transcript": "–ù–∞—á–Ω–µ–º —É—Ä–æ–∫. –ü—Ä–∏–≤–µ—Ç –ø–æ –∫–∏—Ç–∞–π—Å–∫–∏ –±—É–¥–µ—Ç –ù–ò–•–ê–û. –ö–∞–∫ –¥–µ–ª–∞? –ë—É–¥–µ—Ç –ù–ò–•–ê–û –ú–ê. –ß—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ø —Ö–æ—Ä–æ—à–æ, –Ω–∞–¥–æ —Å–∫–∞–∑–∞—Ç—å –í–û–•–≠–ù–•–ê–û."
        },
        {
            "name": "–ü—Ä–æ—â–∞–Ω–∏–µ",
            "transcript": "–£—Ä–æ–∫ –∑–∞–∫–æ–Ω—á–µ–Ω. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è –ø–æ –∫–∏—Ç–∞–π—Å–∫–∏ –¶–ó–ê–ô–¶–ó–Ø–ù–¨. –£–≤–∏–¥–∏–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —É—Ä–æ–∫–µ."
        }
    ]
    
    demo = DualLanguageDemo()
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüß™ –¢–µ—Å—Ç {i}: {test_case['name']}")
        
        comparison = await demo.compare_approaches(test_case["transcript"])
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥:")
        print(f"   –¢–µ–∫—Å—Ç: {comparison['standard']['text'][:100]}...")
        print(f"   –ö–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: {comparison['comparison']['chinese_chars']['standard']}")
        
        print(f"\nDual-Language –º–µ—Ç–æ–¥:")
        print(f"   –¢–µ–∫—Å—Ç: {comparison['dual_language']['text'][:100]}...")
        print(f"   –ö–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: {comparison['comparison']['chinese_chars']['dual_language']}")
        
        print(f"\n‚ú® –£–ª—É—á—à–µ–Ω–∏—è:")
        print(f"   + {comparison['comparison']['chinese_chars']['improvement']} –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   + {comparison['comparison']['text_length']['improvement']} —Å–∏–º–≤–æ–ª–æ–≤ –æ–±—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {comparison['comparison']['recommended']}")
        
        if i < len(test_cases):
            print("\n" + "-" * 80)


async def show_api_examples():
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã API"""
    
    print("\n" + "=" * 80)
    print("üåê –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ API:")
    print("=" * 80)
    
    examples = [
        {
            "title": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è enhanced —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è",
            "endpoint": "POST /lessons/test-enhanced-transcription",
            "curl": '''curl -X POST "http://localhost:8000/lessons/test-enhanced-transcription" \\
     -H "Content-Type: application/json" \\
     -d '{
         "recording_id": "your_recording_id",
         "lesson_type": "chinese",
         "use_multiple_approaches": true
     }' '''
        },
        {
            "title": "–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π dual-language –∞–Ω–∞–ª–∏–∑",
            "endpoint": "POST /lessons/test-dual-language-comparison", 
            "curl": '''curl -X POST "http://localhost:8000/lessons/test-dual-language-comparison" \\
     -H "Content-Type: application/json" \\
     -d '{
         "recording_id": "your_recording_id",
         "lesson_type": "chinese",
         "use_multiple_approaches": true
     }' '''
        }
    ]
    
    for example in examples:
        print(f"üì° {example['title']}:")
        print(f"   Endpoint: {example['endpoint']}")
        print(f"   –ö–æ–º–∞–Ω–¥–∞:")
        print(f"{example['curl']}")
        print()


async def show_summary():
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ"""
    
    print("=" * 80)
    print("üìù –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤:")
    print("=" * 80)
    
    comparison_table = [
        ["–ê—Å–ø–µ–∫—Ç", "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π", "Dual-Language"],
        ["–°–∫–æ—Ä–æ—Å—Ç—å", "üü¢ –ë—ã—Å—Ç—Ä—ã–π", "üü° –ú–µ–¥–ª–µ–Ω–Ω–µ–µ"],
        ["–¢–æ—á–Ω–æ—Å—Ç—å –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ", "üü° –ë–∞–∑–æ–≤–∞—è", "üü¢ –í—ã—Å–æ–∫–∞—è"],
        ["–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä—É—Å—Å–∫–æ–≥–æ", "üü¢ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è", "üü¢ –£–ª—É—á—à–∞–µ—Ç—Å—è"],
        ["–¢–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è", "üî¥ –ù–µ—Ç", "üü¢ –ü–æ–ª–Ω—ã–µ"],
        ["–ê–Ω–∞–ª–∏—Ç–∏–∫–∞", "üî¥ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è", "üü¢ –ü–æ–¥—Ä–æ–±–Ω–∞—è"],
        ["–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ—Å—Ç—å", "üü° –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è", "üü¢ –í—ã—Å–æ–∫–∞—è"]
    ]
    
    for row in comparison_table:
        print(f"{row[0]:<25} | {row[1]:<20} | {row[2]:<20}")
        if row[0] == "–ê—Å–ø–µ–∫—Ç":
            print("-" * 70)
    
    print("\nüéØ –í—ã–≤–æ–¥:")
    print("Dual-Language –ø–æ–¥—Ö–æ–¥ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
    print("—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —É—Ä–æ–∫–æ–≤ –∑–∞ —Å—á–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print("–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.")
    
    print("\nüîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞:")
    print("–î–æ–±–∞–≤—å—Ç–µ –≤ .env —Ñ–∞–π–ª:")
    print("YANDEX_FOLDER_ID=your_folder_id")
    print("YANDEX_API_KEY=your_api_key")
    print("ENABLE_DUAL_LANGUAGE=true")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    await run_demo()
    await show_api_examples()
    await show_summary()


if __name__ == "__main__":
    asyncio.run(main()) 